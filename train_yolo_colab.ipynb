{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warhammer 40K Miniature Detector - YOLO11x Training\n",
    "\n",
    "Train the **best available YOLO model** (YOLO11x - 57M parameters) on your annotated dataset.\n",
    "\n",
    "## Setup\n",
    "1. **Runtime > Change runtime type > T4 GPU** (free tier)\n",
    "2. Upload `yolo_dataset.zip` when prompted\n",
    "3. Run all cells\n",
    "4. Training takes ~2 hours on T4 GPU\n",
    "\n",
    "## Expected Results\n",
    "- Current model (YOLOv8n): 63.2% mAP50\n",
    "- Target (YOLO11x): 75-85% mAP50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install YOLOv8/YOLO11\n",
    "!pip install ultralytics -q\n",
    "print(\"Ultralytics installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Go to Runtime > Change runtime type > T4 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your dataset\n",
    "from google.colab import files\n",
    "print(\"Upload yolo_dataset.zip (49MB)\")\n",
    "print(\"You can find this at: photoanalyzer/backend/yolo_dataset.zip\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset\n",
    "!unzip -q yolo_dataset.zip -d /content/\n",
    "!ls /content/yolo_dataset/\n",
    "\n",
    "import os\n",
    "train_count = len(os.listdir('/content/yolo_dataset/images/train'))\n",
    "val_count = len(os.listdir('/content/yolo_dataset/images/val'))\n",
    "print(f\"\\nTrain images: {train_count}\")\n",
    "print(f\"Val images: {val_count}\")\n",
    "print(f\"Total: {train_count + val_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update data.yaml path for Colab\n",
    "yaml_content = '''# YOLO Dataset Configuration\n",
    "path: /content/yolo_dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "# Classes\n",
    "nc: 8\n",
    "names: [\"adeptus_mechanicus\", \"chaos_space_marines\", \"custodes\", \"death_guard\", \"eldar\", \"genestealer_cult\", \"grey_knights\", \"imperial_guard\"]\n",
    "'''\n",
    "\n",
    "with open('/content/yolo_dataset/data.yaml', 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"data.yaml updated for Colab!\")\n",
    "!cat /content/yolo_dataset/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with YOLO11x\n",
    "\n",
    "YOLO11x is the latest and most accurate YOLO model:\n",
    "- 57M parameters (vs 3M for YOLOv8n)\n",
    "- State-of-the-art accuracy\n",
    "- ~2 hours training on T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO11x - the best model\n",
    "model = YOLO('yolo11x.pt')\n",
    "print(\"YOLO11x loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with optimal settings\n",
    "results = model.train(\n",
    "    data='/content/yolo_dataset/data.yaml',\n",
    "    \n",
    "    # Training duration\n",
    "    epochs=100,\n",
    "    patience=15,  # Early stopping\n",
    "    \n",
    "    # Resolution\n",
    "    imgsz=640,\n",
    "    \n",
    "    # Batch size (adjust if out of memory)\n",
    "    batch=16,\n",
    "    \n",
    "    # Augmentation\n",
    "    degrees=15,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    shear=5,\n",
    "    flipud=0.1,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.15,\n",
    "    copy_paste=0.1,\n",
    "    \n",
    "    # Regularization\n",
    "    dropout=0.1,\n",
    "    \n",
    "    # Output\n",
    "    save=True,\n",
    "    save_period=10,\n",
    "    project='/content/runs',\n",
    "    name='warhammer_yolo11x',\n",
    "    exist_ok=True,\n",
    "    verbose=True,\n",
    "    plots=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View training results\n",
    "from IPython.display import Image, display\n",
    "display(Image('/content/runs/warhammer_yolo11x/results.png', width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View confusion matrix\n",
    "display(Image('/content/runs/warhammer_yolo11x/confusion_matrix.png', width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate and show final metrics\n",
    "best_model = YOLO('/content/runs/warhammer_yolo11x/weights/best.pt')\n",
    "metrics = best_model.val(data='/content/yolo_dataset/data.yaml')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL MODEL METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"mAP50:     {metrics.box.map50:.1%}\")\n",
    "print(f\"mAP50-95:  {metrics.box.map:.1%}\")\n",
    "print(f\"Precision: {metrics.box.mp:.1%}\")\n",
    "print(f\"Recall:    {metrics.box.mr:.1%}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on validation images\n",
    "import os\n",
    "val_images = os.listdir('/content/yolo_dataset/images/val/')[:6]\n",
    "\n",
    "for img in val_images:\n",
    "    results = best_model.predict(\n",
    "        f'/content/yolo_dataset/images/val/{img}',\n",
    "        save=True,\n",
    "        project='/content/predictions',\n",
    "        conf=0.25\n",
    "    )\n",
    "    print(f\"Processed {img}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predictions\n",
    "import glob\n",
    "pred_images = sorted(glob.glob('/content/predictions/predict/*.jpg'))[:6]\n",
    "for img in pred_images:\n",
    "    print(f\"\\n{os.path.basename(img)}\")\n",
    "    display(Image(img, width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Trained Model\n",
    "\n",
    "Download the best model weights to use in your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the trained model\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading best.pt (~110MB)...\")\n",
    "files.download('/content/runs/warhammer_yolo11x/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Download all training artifacts\n",
    "!zip -r /content/training_results.zip /content/runs/warhammer_yolo11x/\n",
    "files.download('/content/training_results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model\n",
    "\n",
    "After downloading, use the model like this:\n",
    "\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Run inference\n",
    "results = model.predict('image.jpg', conf=0.25)\n",
    "\n",
    "# Get detections\n",
    "for r in results:\n",
    "    for box in r.boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        name = model.names[cls]\n",
    "        print(f\"{name}: {conf:.1%}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
